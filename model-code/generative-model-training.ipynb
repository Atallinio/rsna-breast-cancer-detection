{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":39272,"databundleVersionId":4629629,"sourceType":"competition"},{"sourceId":4913500,"sourceType":"datasetVersion","datasetId":2849545},{"sourceId":136060,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":115125,"modelId":138388},{"sourceId":139209,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":117879,"modelId":141116}],"dockerImageVersionId":30788,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/joeatallah/rsna-breast-cancer-detection-cvae-training?scriptVersionId=200916970\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"# RSNA Breast Cancer Detection\n\n*The following is a solution to the RSNA Screeening Mammography Breast Cancer Detection Dataset*","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_io as tfio\nimport tensorflow_datasets as tfds\nimport tensorflow.keras.backend as K\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.model_selection import train_test_split\n\n\nimport cv2\n\nimport time\nimport keras\nimport os\nimport logging\nimport random\nimport math","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:25.404943Z","iopub.execute_input":"2024-10-18T04:42:25.405352Z","iopub.status.idle":"2024-10-18T04:42:43.786808Z","shell.execute_reply.started":"2024-10-18T04:42:25.405321Z","shell.execute_reply":"2024-10-18T04:42:43.785760Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on CPU or GPU')\n    TPU = None\n\nif TPU:\n    IS_TPU = True\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    IS_TPU = False\n    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\n#clear_output()\nN_REPLICAS = STRATEGY.num_replicas_in_sync\nprint(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:43.788570Z","iopub.execute_input":"2024-10-18T04:42:43.789095Z","iopub.status.idle":"2024-10-18T04:42:52.651982Z","shell.execute_reply.started":"2024-10-18T04:42:43.789063Z","shell.execute_reply":"2024-10-18T04:42:52.651053Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Image dimensions\nIMG_HEIGHT = 1456\nIMG_WIDTH = 728\nN_CHANNELS = 1\nINPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\nN_SAMPLES_TFRECORDS = 548\n\n# Peak Learning Rate\nEPOCHS = 15\n\n# Batch size\nBATCH_SIZE = 4 * N_REPLICAS\n\n\nIS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\nVERBOSE = 1 if IS_INTERACTIVE else 2\n\n# Tensorflow AUTO flag\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(f'BATCH_SIZE: {BATCH_SIZE}')","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:52.653142Z","iopub.execute_input":"2024-10-18T04:42:52.653393Z","iopub.status.idle":"2024-10-18T04:42:52.659218Z","shell.execute_reply.started":"2024-10-18T04:42:52.653367Z","shell.execute_reply":"2024-10-18T04:42:52.658316Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MIXED_PRECISION = False\nDEVICE = 'TPU'\n\nif MIXED_PRECISION:\n    if 'TPU' in DEVICE:\n        policy_type = 'mixed_bfloat16'\n    else:\n        policy_type = 'mixed_float16'\nelse:\n    policy_type = 'float32'\npolicy = tf.keras.mixed_precision.Policy(policy_type)\ntf.keras.mixed_precision.set_global_policy(policy)\nprint(f'Computation dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\nprint(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:52.661087Z","iopub.execute_input":"2024-10-18T04:42:52.661379Z","iopub.status.idle":"2024-10-18T04:42:52.676477Z","shell.execute_reply.started":"2024-10-18T04:42:52.661352Z","shell.execute_reply":"2024-10-18T04:42:52.675556Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# TFRecord file paths\ntfrecords = sorted(tf.io.gfile.glob('/kaggle/input/dataset-rsna-bcd-1456x728-final-tfrecords/*.tfrecords'))\nprint(f'Found {len(tfrecords)} TFRecords')\n\nTRAIN_STEPS_PER_EPOCH = 835 #batchsize = 64","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:52.677581Z","iopub.execute_input":"2024-10-18T04:42:52.677883Z","iopub.status.idle":"2024-10-18T04:42:52.751735Z","shell.execute_reply.started":"2024-10-18T04:42:52.677824Z","shell.execute_reply":"2024-10-18T04:42:52.750664Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dataset(tfrecords):\n    # Load the TFRecord dataset, read in parallel, and decompress using GZIP\n    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n\n    # Apply the decoder function to parse each record\n    dataset = dataset.map(decoder, num_parallel_calls=AUTO)\n    new_dataset = dataset.filter(undersample_majority)\n    \n    # Filter the dataset into cancer and non-cancer subsets\n    cancer_dataset = dataset.filter(cancer)\n    non_cancer_dataset = dataset.filter(non_cancer)\n    \n    # Preprocess each dataset (shuffle, batch, prefetch)\n    cancer_dataset = preprocess(cancer_dataset)\n    non_cancer_dataset = preprocess(non_cancer_dataset)\n    new_dataset = new_dataset.batch(1).prefetch(AUTO)\n    #new_dataset = preprocess(new_dataset)\n    \n    # For the cancer dataset, map the return_image function to return the image only\n    cancer_dataset = cancer_dataset.map(return_image, num_parallel_calls=AUTO)\n    \n    # For the non-cancer dataset, map the return_images function to return the image twice\n    non_cancer_dataset = non_cancer_dataset.map(return_images, num_parallel_calls=AUTO)\n    \n    # Return the cancer, non-cancer, and the original datasets\n    return cancer_dataset, non_cancer_dataset, new_dataset\n\n\ndef preprocess(dataset):\n    # Set options to allow non-deterministic order for performance improvements\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    dataset = dataset.with_options(ignore_order)\n    \n    # Shuffle, batch, and prefetch the dataset for optimized pipeline execution\n    dataset = dataset.shuffle(1024)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    \n    return dataset\n\n\ndef decoder(record_bytes):\n    # Parse the TFRecord example to extract image, target label, and patient ID\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64)})\n    \n    # Decode the image, reshape it, and normalize pixel values to the range [0, 1]\n    img = tf.io.decode_png(features['image'], channels=N_CHANNELS)\n    img = tf.reshape(img, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n    img = img / 255\n    img = tf.cast(img, tf.float32)\n    \n    # Extract the target label (e.g., 0 for non-cancer, 1 for cancer)\n    label = features['target']\n    \n    return img, label\n\n\ndef cancer(img, label):\n    # Return True if the label indicates cancer (1), used for filtering\n    return label == 1\n\n\ndef non_cancer(img, label):\n    # Return True if the label indicates non-cancer (0), used for filtering\n    return label == 0\n\n\ndef return_images(img, label):\n    # Return the image twice (used for non-cancer dataset)\n    return img, img\n\n\ndef return_image(img, label):\n    # Return only the image (used for cancer dataset)\n    return img\n\ndef undersample_majority(img, label):\n    # Create a more balanced dataset\n    return label == 1 or tf.random.uniform([]) > 3/4","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:52.752974Z","iopub.execute_input":"2024-10-18T04:42:52.753327Z","iopub.status.idle":"2024-10-18T04:42:52.765662Z","shell.execute_reply.started":"2024-10-18T04:42:52.753296Z","shell.execute_reply":"2024-10-18T04:42:52.764656Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get Cancer/Non-Cancer datasets\nc_dataset, nc_dataset, dataset = create_dataset(tfrecords)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:52.766825Z","iopub.execute_input":"2024-10-18T04:42:52.767130Z","iopub.status.idle":"2024-10-18T04:42:53.056713Z","shell.execute_reply.started":"2024-10-18T04:42:52.767102Z","shell.execute_reply":"2024-10-18T04:42:53.055649Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(next(iter(nc_dataset))[0][0].numpy())","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:53.057903Z","iopub.execute_input":"2024-10-18T04:42:53.058225Z","iopub.status.idle":"2024-10-18T04:42:54.634686Z","shell.execute_reply.started":"2024-10-18T04:42:53.058193Z","shell.execute_reply":"2024-10-18T04:42:54.633694Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sanity checking\ndef check_dataset(dataset):\n    image, _ = next(iter(dataset))\n    image = image.numpy()\n    print(f\"X_batch shape: {image.shape}\")\n    print(f\"X_batch dtype: {image.dtype}\")\n    print(f\"X_batch min: {image.min():.2f}, max: {image.max():.2f}\")\n\ncheck_dataset(nc_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:54.635826Z","iopub.execute_input":"2024-10-18T04:42:54.636131Z","iopub.status.idle":"2024-10-18T04:42:55.695843Z","shell.execute_reply.started":"2024-10-18T04:42:54.636101Z","shell.execute_reply":"2024-10-18T04:42:55.694813Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# VAE loss function: combines reconstruction loss and KL divergence\ndef vaeloss(y_true, y_pred, mean, logvar):\n    # Reconstruction loss: measures the difference between the original and predicted images (scaled by image size)\n    reconstruction_loss = K.sqrt(K.mean(K.square(y_true - y_pred), axis=[1, 2, 3])) * IMG_HEIGHT * IMG_WIDTH\n    \n    # KL divergence: measures how much the learned distribution (mean, logvar) diverges from a standard normal distribution\n    kl_loss = -0.5 * K.sum(1 + logvar - keras.ops.square(mean) - K.exp(logvar), axis=1)\n    \n    # Return the combined loss (average over batch)\n    return K.mean(reconstruction_loss + kl_loss)\n    \n\nclass CVAE(keras.Model):\n    def __init__(self, latent_dim): \n        super(CVAE, self).__init__()\n        self.latent_dim = latent_dim\n        \n        # Encoder\n        inputs = keras.Input((IMG_HEIGHT, IMG_WIDTH, 1))\n        x = keras.ops.image.resize(inputs, (1536,768))\n        x = keras.layers.Conv2D(filters=32, kernel_size=7, strides=(2, 1), padding='same', activation='leaky_relu')(x)\n        x = self.encoder_block(x, 64, 2)\n        x = self.encoder_block(x, 128, 3)\n        x = self.encoder_block(x, 256, 3)\n        x = keras.layers.GlobalAveragePooling2D()(x)\n        encoder_output = keras.layers.Dense(self.latent_dim + self.latent_dim)(x)\n        mean, logvar = keras.ops.split(encoder_output, indices_or_sections=2, axis=1)\n        self.encoder = keras.Model(inputs, (mean, logvar), name=\"encoder\")\n\n        # Decoder\n        latent_inputs = keras.Input((self.latent_dim,))\n        x = keras.layers.Dense(units=32*16*16)(latent_inputs)\n        x = keras.layers.Reshape(target_shape=(32, 16, 16))(x)\n        x = self.decoder_block(x, 256, 2)\n        x = self.decoder_block(x, 128, 3)\n        x = self.decoder_block(x, 64, 3)\n        x = self.decoder_block(x, 32, 2)\n        outputs = keras.layers.Conv2DTranspose(filters=1, kernel_size=7, strides=2, padding='same', activation='sigmoid')(x)\n        outputs = keras.ops.image.resize(outputs, (1456,728))\n        self.decoder = keras.Model(latent_inputs, outputs, name=\"decoder\")\n\n    \n    def resblock(self, x, filters, encoder=True, stride=2, kernel_size=3):\n        x = keras.layers.BatchNormalization()(x)\n        x = keras.layers.LeakyReLU()(x)\n        fx = keras.layers.Conv2D(filters//2, kernel_size=1)(x)\n        \n        fx = keras.layers.BatchNormalization()(fx)\n        fx = keras.layers.LeakyReLU()(fx)\n        if encoder:   \n            fx = keras.layers.Conv2D(filters//2, kernel_size, padding='same', strides=stride)(fx)\n            x = keras.layers.Conv2D(filters, kernel_size=1, strides=stride)(x)\n        else:\n            fx = keras.layers.Conv2DTranspose(filters//2, kernel_size, padding='same', strides=stride)(fx)\n            x = keras.layers.Conv2DTranspose(filters, kernel_size=1, strides=stride)(x)\n            \n        fx = keras.layers.BatchNormalization()(fx)\n        fx = keras.layers.LeakyReLU()(fx)\n        fx = keras.layers.Conv2D(filters, kernel_size=1)(fx)\n\n        out = keras.layers.Add()([x, fx])\n        return out\n    \n    def encoder_block(self, x, filters, blocks, encoder=True, stride=2, kernel_size=3):\n        strides = [stride] + [1]*blocks\n        for stride in strides:\n            x = self.resblock(x, filters, encoder, stride)\n        return x\n            \n    \n    def decoder_block(self, x, filters, blocks, encoder=False, stride=2, kernel_size=3):\n        strides = [stride] + [1]*blocks\n        for stride in strides:\n            x = self.resblock(x, filters, encoder, stride)\n        return x\n    \n    def reparameterize(self, mean, logvar):\n        eps = tf.random.normal(shape=tf.shape(mean))\n        return eps * tf.exp(logvar * 0.5) + mean\n    \n    \n    def get_config(self):\n        return {\"latent_dim\": self.latent_dim}\n    \n    def save_model(self, filepath):\n        self.save(filepath)\n\n    def call(self,x):\n        self.mean, self.logvar = self.encoder(x)\n        output = self.decoder(self.reparameterize(self.mean, self.logvar))\n        self.add_loss(vaeloss(x, output, self.mean, self.logvar))\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:55.698342Z","iopub.execute_input":"2024-10-18T04:42:55.698605Z","iopub.status.idle":"2024-10-18T04:42:55.717081Z","shell.execute_reply.started":"2024-10-18T04:42:55.698579Z","shell.execute_reply":"2024-10-18T04:42:55.716156Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build, Fit and Save the model\n\n'''tf.keras.backend.clear_session()\ntf.config.optimizer.set_jit(\"autoclustering\")\n\nwith STRATEGY.scope():    \n    \n    model = CVAE(1024)\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001))\n    print(model.summary())\n    for i in range(5):\n        history = model.fit(x=nc_dataset, epochs=5, steps_per_epoch=TRAIN_STEPS_PER_EPOCH)\n        model.save_model(f\"/kaggle/working/cvae_model_v{i}.keras\")'''","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:55.718111Z","iopub.execute_input":"2024-10-18T04:42:55.718360Z","iopub.status.idle":"2024-10-18T04:42:55.733931Z","shell.execute_reply.started":"2024-10-18T04:42:55.718335Z","shell.execute_reply":"2024-10-18T04:42:55.733123Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''# Load model\n\n!cp /kaggle/input/cvae_model_v2.keras/keras/default/1/cvae_model_v3.keras /kaggle/working/cvae_model_v2.keras\nwith STRATEGY.scope(): \n    #model.save_model(\"/kaggle/working/cvae_model_v2.keras\")\n    model1 = keras.models.load_model(\"/kaggle/working/cvae_model_v2.keras\", custom_objects={'CVAE': CVAE})\n    #history1 = model1.fit(x=nc_dataset, epochs=1, steps_per_epoch=TRAIN_STEPS_PER_EPOCH)'''","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:42:55.735043Z","iopub.execute_input":"2024-10-18T04:42:55.735382Z","iopub.status.idle":"2024-10-18T04:42:55.748750Z","shell.execute_reply.started":"2024-10-18T04:42:55.735328Z","shell.execute_reply":"2024-10-18T04:42:55.747993Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with STRATEGY.scope(): \n    model = keras.models.load_model(\"/kaggle/input/cvae_model_v4/tensorflow2/default/1/cvae_model_v4.keras\", custom_objects={'CVAE': CVAE})\n    '''for i in range(5):\n        history = model.fit(x=nc_dataset, epochs=5, steps_per_epoch=TRAIN_STEPS_PER_EPOCH)\n        model.save_model(f\"/kaggle/working/cvae_model_v{i}.keras\")'''","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:43:26.060653Z","iopub.execute_input":"2024-10-18T04:43:26.061039Z","iopub.status.idle":"2024-10-18T04:44:02.507736Z","shell.execute_reply.started":"2024-10-18T04:43:26.060996Z","shell.execute_reply":"2024-10-18T04:44:02.506640Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot generated images with original\ndef plot_predictions(model, validation_data):\n    for x in validation_data.take(1):\n        '''mean, logvar = model.encoder(test_x)\n        z = model.reparameterize(mean, logvar)\n        pred = model.decoder(z)'''\n        with STRATEGY.scope():\n            pred = model(x)\n        \n        fig = plt.figure(figsize=(16, 16))\n\n        for i in range(min(BATCH_SIZE,8)):\n            plt.subplot(4, 4, i + 1)\n            plt.imshow(pred[i,:,:,:], cmap='jet')\n            plt.axis('off')\n        plt.show()\n\n        fig1 = plt.figure(figsize=(16, 16))\n\n        for i in range(min(BATCH_SIZE,8)):\n            plt.subplot(4, 4, i + 1)\n            plt.imshow(x[i, :, :, ], cmap='jet')\n            plt.axis('off')\n\n        plt.show()\nplot_predictions(model, c_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:44:02.509836Z","iopub.execute_input":"2024-10-18T04:44:02.510139Z","iopub.status.idle":"2024-10-18T04:45:02.326168Z","shell.execute_reply.started":"2024-10-18T04:44:02.510108Z","shell.execute_reply":"2024-10-18T04:45:02.325257Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Calculating an optimal threshold\n\nNow I will compute an **anomaly score** for each input image, store these scores along with their corresponding labels, and then use the **ROC curve** to identify the optimal threshold for distinguishing between normal and anomalous data.","metadata":{}},{"cell_type":"code","source":"all_labels = []\nall_scores = []\n\n@tf.function\ndef test(x):\n    \n    model.mean, model.logvar = model.encoder(images)\n    output = model.decoder(model.reparameterize(model.mean, model.logvar))\n    anomaly_score = vaeloss(images, output, model.mean, model.logvar)\n    return anomaly_score\n#with STRATEGY.scope():\nc = 0\nfor images, labels in dataset:  \n    if c % 1000 == 0: \n        print(c)\n    anomaly_score = test(images)\n    all_labels.append(labels.numpy())  \n    all_scores.append(anomaly_score) \n    c += 1\n\n# Convert lists to numpy arrays\nall_labels = np.array(all_labels)\nall_scores = np.array(all_scores)\n\n# Calculate the ROC curve\nfpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n\n# Determine the optimal threshold\noptimal_threshold = thresholds[np.argmax(tpr - fpr)]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:45:02.327348Z","iopub.execute_input":"2024-10-18T04:45:02.327602Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimal_threshold","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the ROC curve\ndef plot_roc_curve(y_true, anomaly_scores):\n    # Calculate ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true, anomaly_scores)\n    \n    # Calculate AUC\n    roc_auc = auc(fpr, tpr)\n    \n    # Plot ROC curve\n    plt.figure(figsize=(10, 8))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    \n    # Add threshold annotations\n    thresholds_to_show = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n    idx = np.searchsorted(thresholds, thresholds_to_show)\n    for i in idx:\n        plt.annotate(f'{thresholds[i]:.2f}', (fpr[i], tpr[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n\n    # Find and mark the optimal threshold\n    optimal_idx = np.argmax(tpr - fpr)\n    optimal_threshold = thresholds[optimal_idx]\n    plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=10, label=f'Optimal threshold: {optimal_threshold:.2f}')\n    plt.annotate(f'Optimal: {optimal_threshold:.2f}', (fpr[optimal_idx], tpr[optimal_idx]), \n                 textcoords=\"offset points\", xytext=(0,-20), ha='center', fontweight='bold')\n\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    plt.show()\n\n    return optimal_threshold\n\nplot_roc_curve(all_labels, all_scores)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T03:31:14.844594Z","iopub.execute_input":"2024-10-15T03:31:14.844937Z","iopub.status.idle":"2024-10-15T03:31:15.045188Z","shell.execute_reply.started":"2024-10-15T03:31:14.844909Z","shell.execute_reply":"2024-10-15T03:31:15.044395Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prediction (Calculating model pf1 score)","metadata":{}},{"cell_type":"code","source":"'''pred = list()\ny = list()\n\nfor images, labels in dataset.take(200):  \n    model1.mean, model1.logvar = model1.encoder(images)\n    output = model1.decoder(model1.reparameterize(model1.mean, model1.logvar))\n    error = vaeloss(images, output, model1.mean, model1.logvar)\n    \n    y.append(labels.numpy()[0])\n    if error > optimal_threshold:\n        pred.append(1)\n    else:\n        pred.append(0)\n'''","metadata":{"execution":{"iopub.status.busy":"2024-10-18T04:41:58.731267Z","iopub.execute_input":"2024-10-18T04:41:58.731533Z","iopub.status.idle":"2024-10-18T04:41:58.739471Z","shell.execute_reply.started":"2024-10-18T04:41:58.731507Z","shell.execute_reply":"2024-10-18T04:41:58.738759Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = list()\nfor i in list(all_scores):\n    if i > optimal_threshold:\n        pred.append(1)\n    else:\n        pred.append(0)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T03:34:55.460280Z","iopub.execute_input":"2024-10-15T03:34:55.460662Z","iopub.status.idle":"2024-10-15T03:34:55.465906Z","shell.execute_reply.started":"2024-10-15T03:34:55.460633Z","shell.execute_reply":"2024-10-15T03:34:55.464729Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pfbeta(labels, predictions, beta=1):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = predictions[idx]\n\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n    print(y_true_count)\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0\n\nresult = pfbeta(all_labels,pred)\nresult","metadata":{"execution":{"iopub.status.busy":"2024-10-15T03:35:16.127406Z","iopub.execute_input":"2024-10-15T03:35:16.127846Z","iopub.status.idle":"2024-10-15T03:35:16.137465Z","shell.execute_reply.started":"2024-10-15T03:35:16.127811Z","shell.execute_reply":"2024-10-15T03:35:16.136549Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''# Calculate number of cancer images in the batch used\nfor n, i in enumerate(y):\n    if i == 1:\n        print(n)'''","metadata":{"execution":{"iopub.status.busy":"2024-10-10T01:44:55.799421Z","iopub.execute_input":"2024-10-10T01:44:55.799823Z","iopub.status.idle":"2024-10-10T01:44:55.805569Z","shell.execute_reply.started":"2024-10-10T01:44:55.799793Z","shell.execute_reply":"2024-10-10T01:44:55.804463Z"},"trusted":true},"outputs":[],"execution_count":null}]}