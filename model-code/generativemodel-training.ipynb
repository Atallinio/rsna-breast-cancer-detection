{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":39272,"databundleVersionId":4629629,"sourceType":"competition"},{"sourceId":4913500,"sourceType":"datasetVersion","datasetId":2849545},{"sourceId":9517278,"sourceType":"datasetVersion","datasetId":5794187}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/joeatallah/rsna-breast-cancer-detection-cvae-training?scriptVersionId=210016149\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# RSNA Breast Cancer Detection\n\n*The following is a solution to the RSNA Screeening Mammography Breast Cancer Detection Dataset*","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_io as tfio\nimport tensorflow_datasets as tfds\nimport tensorflow.keras.backend as K\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.model_selection import train_test_split\n\n\nimport cv2\n\nimport time\nimport keras\nimport os\nimport logging\nimport random\nimport math","metadata":{"execution":{"iopub.status.busy":"2024-10-09T23:09:12.251104Z","iopub.execute_input":"2024-10-09T23:09:12.25151Z","iopub.status.idle":"2024-10-09T23:09:28.651328Z","shell.execute_reply.started":"2024-10-09T23:09:12.251477Z","shell.execute_reply":"2024-10-09T23:09:28.650475Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on CPU or GPU')\n    TPU = None\n\nif TPU:\n    IS_TPU = True\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    IS_TPU = False\n    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\n#clear_output()\nN_REPLICAS = STRATEGY.num_replicas_in_sync\nprint(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T23:09:28.652973Z","iopub.execute_input":"2024-10-09T23:09:28.653596Z","iopub.status.idle":"2024-10-09T23:09:28.664044Z","shell.execute_reply.started":"2024-10-09T23:09:28.653563Z","shell.execute_reply":"2024-10-09T23:09:28.662877Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Image dimensions\nIMG_HEIGHT = 1456\nIMG_WIDTH = 728\nN_CHANNELS = 1\nINPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\nN_SAMPLES_TFRECORDS = 548\n\n# Peak Learning Rate\nEPOCHS = 15\n\n# Batch size\nBATCH_SIZE = 8 * N_REPLICAS\n\n\nIS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\nVERBOSE = 1 if IS_INTERACTIVE else 2\n\n# Tensorflow AUTO flag\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(f'BATCH_SIZE: {BATCH_SIZE}')","metadata":{"execution":{"iopub.status.busy":"2024-10-10T02:41:54.126531Z","iopub.execute_input":"2024-10-10T02:41:54.12695Z","iopub.status.idle":"2024-10-10T02:41:54.13438Z","shell.execute_reply.started":"2024-10-10T02:41:54.126915Z","shell.execute_reply":"2024-10-10T02:41:54.133378Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MIXED_PRECISION = False\nDEVICE = 'TPU'\n\nif MIXED_PRECISION:\n    if 'TPU' in DEVICE:\n        policy_type = 'mixed_bfloat16'\n    else:\n        policy_type = 'mixed_float16'\nelse:\n    policy_type = 'float32'\npolicy = tf.keras.mixed_precision.Policy(policy_type)\ntf.keras.mixed_precision.set_global_policy(policy)\nprint(f'Computation dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\nprint(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')","metadata":{"execution":{"iopub.status.busy":"2024-10-10T02:41:54.448021Z","iopub.execute_input":"2024-10-10T02:41:54.448391Z","iopub.status.idle":"2024-10-10T02:41:54.4559Z","shell.execute_reply.started":"2024-10-10T02:41:54.448363Z","shell.execute_reply":"2024-10-10T02:41:54.454761Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# TFRecord file paths\ntfrecords = sorted(tf.io.gfile.glob('/kaggle/input/dataset-rsna-bcd-1456x728-final-tfrecords/*.tfrecords'))\nprint(f'Found {len(tfrecords)} TFRecords')\n\nTRAIN_STEPS_PER_EPOCH = 835 #batchsize = 64","metadata":{"execution":{"iopub.status.busy":"2024-10-10T02:41:54.71492Z","iopub.execute_input":"2024-10-10T02:41:54.715322Z","iopub.status.idle":"2024-10-10T02:41:54.724379Z","shell.execute_reply.started":"2024-10-10T02:41:54.715287Z","shell.execute_reply":"2024-10-10T02:41:54.7232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dataset(tfrecords):\n    # Load the TFRecord dataset, read in parallel, and decompress using GZIP\n    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n\n    # Apply the decoder function to parse each record\n    dataset = dataset.map(decoder, num_parallel_calls=AUTO)\n    new_dataset = dataset.filter(undersample_majority)\n    \n    # Filter the dataset into cancer and non-cancer subsets\n    cancer_dataset = dataset.filter(cancer)\n    non_cancer_dataset = dataset.filter(non_cancer)\n    \n    # Preprocess each dataset (shuffle, batch, prefetch)\n    cancer_dataset = preprocess(cancer_dataset)\n    non_cancer_dataset = preprocess(non_cancer_dataset)\n    dataset = preprocess(dataset)\n    \n    # For the cancer dataset, map the return_image function to return the image only\n    cancer_dataset = cancer_dataset.map(return_image, num_parallel_calls=AUTO)\n    \n    # For the non-cancer dataset, map the return_images function to return the image twice\n    non_cancer_dataset = non_cancer_dataset.map(return_images, num_parallel_calls=AUTO)\n    \n    # Return the cancer, non-cancer, and the original datasets\n    return cancer_dataset, non_cancer_dataset, new_dataset\n\n\ndef preprocess(dataset):\n    # Set options to allow non-deterministic order for performance improvements\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    dataset = dataset.with_options(ignore_order)\n    \n    # Shuffle, batch, and prefetch the dataset for optimized pipeline execution\n    dataset = dataset.shuffle(1024)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    \n    return dataset\n\n\ndef decoder(record_bytes):\n    # Parse the TFRecord example to extract image, target label, and patient ID\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64)})\n    \n    # Decode the image, reshape it, and normalize pixel values to the range [0, 1]\n    img = tf.io.decode_png(features['image'], channels=N_CHANNELS)\n    img = tf.reshape(img, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n    img = img / 255\n    img = tf.cast(img, tf.float32)\n    \n    # Extract the target label (e.g., 0 for non-cancer, 1 for cancer)\n    label = features['target']\n    \n    return img, label\n\n\ndef cancer(img, label):\n    # Return True if the label indicates cancer (1), used for filtering\n    return label == 1\n\n\ndef non_cancer(img, label):\n    # Return True if the label indicates non-cancer (0), used for filtering\n    return label == 0\n\n\ndef return_images(img, label):\n    # Return the image twice (used for non-cancer dataset)\n    return img, img\n\n\ndef return_image(img, label):\n    # Return only the image (used for cancer dataset)\n    return img\n\ndef undersample_majority(img, label):\n    # Create a more balanced dataset\n    return label == 1 or tf.random.uniform([]) > 3/4","metadata":{"execution":{"iopub.status.busy":"2024-10-10T02:41:55.103235Z","iopub.execute_input":"2024-10-10T02:41:55.103641Z","iopub.status.idle":"2024-10-10T02:41:55.118307Z","shell.execute_reply.started":"2024-10-10T02:41:55.103601Z","shell.execute_reply":"2024-10-10T02:41:55.117245Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get Cancer/Non-Cancer datasets\nc_dataset, nc_dataset, dataset = create_dataset(tfrecords)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T02:41:55.41245Z","iopub.execute_input":"2024-10-10T02:41:55.412864Z","iopub.status.idle":"2024-10-10T02:41:55.563718Z","shell.execute_reply.started":"2024-10-10T02:41:55.412829Z","shell.execute_reply":"2024-10-10T02:41:55.562777Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(next(iter(nc_dataset))[0][0].numpy())","metadata":{"execution":{"iopub.status.busy":"2024-10-09T23:09:29.852485Z","iopub.execute_input":"2024-10-09T23:09:29.853293Z","iopub.status.idle":"2024-10-09T23:09:34.993171Z","shell.execute_reply.started":"2024-10-09T23:09:29.853255Z","shell.execute_reply":"2024-10-09T23:09:34.992158Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sanity checking\ndef check_dataset(dataset):\n    image, _ = next(iter(dataset))\n    image = image.numpy()\n    print(f\"X_batch shape: {image.shape}\")\n    print(f\"X_batch dtype: {image.dtype}\")\n    print(f\"X_batch min: {image.min():.2f}, max: {image.max():.2f}\")\n\ncheck_dataset(nc_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T02:42:01.869519Z","iopub.execute_input":"2024-10-10T02:42:01.869882Z","iopub.status.idle":"2024-10-10T02:42:06.575783Z","shell.execute_reply.started":"2024-10-10T02:42:01.869853Z","shell.execute_reply":"2024-10-10T02:42:06.574808Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# VAE loss function: combines reconstruction loss and KL divergence\ndef vaeloss(y_true, y_pred, mean, logvar):\n    # Reconstruction loss: measures the difference between the original and predicted images (scaled by image size)\n    reconstruction_loss = K.sqrt(K.mean(K.square(y_true - y_pred), axis=[1, 2, 3])) * IMG_HEIGHT * IMG_WIDTH\n    \n    # KL divergence: measures how much the learned distribution (mean, logvar) diverges from a standard normal distribution\n    kl_loss = -0.5 * K.sum(1 + logvar - keras.ops.square(mean) - K.exp(logvar), axis=1)\n    \n    # Return the combined loss (average over batch)\n    return K.mean(reconstruction_loss + kl_loss)\n    \n\nclass CVAE(keras.Model):\n    def __init__(self, latent_dim): \n        super(CVAE, self).__init__()\n        self.latent_dim = latent_dim\n        \n        # Encoder\n        inputs = keras.Input((IMG_HEIGHT, IMG_WIDTH, 1))\n        x = keras.ops.image.resize(inputs, (1536,768))\n        x = keras.layers.Conv2D(filters=32, kernel_size=7, strides=(2, 1), padding='same', activation='leaky_relu')(x)\n        x = self.encoder_block(x, 64, 2)\n        x = self.encoder_block(x, 128, 3)\n        x = self.encoder_block(x, 256, 3)\n        x = self.encoder_block(x, 512, 2)\n        x = keras.layers.GlobalAveragePooling2D()(x)\n        encoder_output = keras.layers.Dense(self.latent_dim + self.latent_dim)(x)\n        mean, logvar = keras.ops.split(encoder_output, indices_or_sections=2, axis=1)\n        self.encoder = keras.Model(inputs, (mean, logvar), name=\"encoder\")\n\n        # Decoder\n        latent_inputs = keras.Input((self.latent_dim,))\n        x = keras.layers.Dense(units=64*32*16)(latent_inputs)\n        x = keras.layers.Reshape(target_shape=(64, 32, 16))(x)\n        x = self.decoder_block(x, 256, 2)\n        x = self.decoder_block(x, 128, 3)\n        x = self.decoder_block(x, 64, 3)\n        x = self.decoder_block(x, 32, 2)\n        outputs = keras.layers.Conv2DTranspose(filters=1, kernel_size=7, strides=2, padding='same', activation='sigmoid')(x)\n        outputs = keras.ops.image.resize(outputs, (1456,728))\n        self.decoder = keras.Model(latent_inputs, outputs, name=\"decoder\")\n\n    \n    def resblock(self, x, filters, encoder=True, stride=2, kernel_size=3):\n        x = keras.layers.BatchNormalization()(x)\n        x = keras.layers.LeakyReLU()(x)\n        fx = keras.layers.Conv2D(filters//2, kernel_size=1)(x)\n        \n        fx = keras.layers.BatchNormalization()(fx)\n        fx = keras.layers.LeakyReLU()(fx)\n        if encoder:   \n            fx = keras.layers.Conv2D(filters//2, kernel_size, padding='same', strides=stride)(fx)\n            x = keras.layers.Conv2D(filters, kernel_size=1, strides=stride)(x)\n        else:\n            fx = keras.layers.Conv2DTranspose(filters//2, kernel_size, padding='same', strides=stride)(fx)\n            x = keras.layers.Conv2DTranspose(filters, kernel_size=1, strides=stride)(x)\n            \n        fx = keras.layers.BatchNormalization()(fx)\n        fx = keras.layers.LeakyReLU()(fx)\n        fx = keras.layers.Conv2D(filters, kernel_size=1)(fx)\n\n        out = keras.layers.Add()([x, fx])\n        return out\n    \n    def encoder_block(self, x, filters, blocks, encoder=True, stride=2, kernel_size=3):\n        strides = [stride] + [1]*blocks\n        for stride in strides:\n            x = self.resblock(x, filters, encoder, stride)\n        return x\n            \n    \n    def decoder_block(self, x, filters, blocks, encoder=False, stride=2, kernel_size=3):\n        strides = [stride] + [1]*blocks\n        for stride in strides:\n            x = self.resblock(x, filters, encoder, stride)\n        return x\n    \n    def reparameterize(self, mean, logvar):\n        eps = tf.random.normal(shape=tf.shape(mean))\n        return eps * tf.exp(logvar * 0.5) + mean\n    \n    \n    def get_config(self):\n        return {\"latent_dim\": self.latent_dim}\n    \n    def save_model(self, filepath):\n        self.save(filepath)\n\n    def call(self,x):\n        self.mean, self.logvar = self.encoder(x)\n        output = self.decoder(self.reparameterize(self.mean, self.logvar))\n        self.add_loss(vaeloss(x, output, self.mean, self.logvar))\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-10-10T02:42:11.765329Z","iopub.execute_input":"2024-10-10T02:42:11.766158Z","iopub.status.idle":"2024-10-10T02:42:11.793956Z","shell.execute_reply.started":"2024-10-10T02:42:11.766101Z","shell.execute_reply":"2024-10-10T02:42:11.792821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build, Fit and Save the model\n\ntf.keras.backend.clear_session()\ntf.config.optimizer.set_jit(\"autoclustering\")\n\nwith STRATEGY.scope():    \n    \n    model = CVAE(1024)\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n    print(model.summary())\n    history = model.fit(x=nc_dataset, epochs=60, steps_per_epoch=TRAIN_STEPS_PER_EPOCH)\n    model.save_model(\"/kaggle/working/cvae_model_v3.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-10-10T02:42:15.569707Z","iopub.execute_input":"2024-10-10T02:42:15.570465Z","iopub.status.idle":"2024-10-10T02:48:42.003976Z","shell.execute_reply.started":"2024-10-10T02:42:15.570426Z","shell.execute_reply":"2024-10-10T02:48:42.002156Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load model\n\n!cp /kaggle/input/cvae_model_v2.keras/keras/default/1/cvae_model_v3.keras /kaggle/working/cvae_model_v2.keras\nwith STRATEGY.scope(): \n    #model.save_model(\"/kaggle/working/cvae_model_v2.keras\")\n    model1 = keras.models.load_model(\"/kaggle/working/cvae_model_v2.keras\", custom_objects={'CVAE': CVAE})\n    #history1 = model1.fit(x=nc_dataset, epochs=1, steps_per_epoch=TRAIN_STEPS_PER_EPOCH)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T23:09:39.474947Z","iopub.execute_input":"2024-10-09T23:09:39.475281Z","iopub.status.idle":"2024-10-09T23:09:47.276318Z","shell.execute_reply.started":"2024-10-09T23:09:39.475255Z","shell.execute_reply":"2024-10-09T23:09:47.274851Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''with STRATEGY.scope():  \n    history = model.fit(x=nc_dataset, epochs=5, steps_per_epoch=TRAIN_STEPS_PER_EPOCH)\n    model.save(\"/kaggle/working/cvae_model_v2.keras\")'''","metadata":{"execution":{"iopub.status.busy":"2024-10-09T23:09:12.219555Z","iopub.execute_input":"2024-10-09T23:09:12.22038Z","iopub.status.idle":"2024-10-09T23:09:12.228198Z","shell.execute_reply.started":"2024-10-09T23:09:12.22033Z","shell.execute_reply":"2024-10-09T23:09:12.226883Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot generated images with original\ndef plot_predictions(model, validation_data):\n    for x in validation_data.take(1):\n        '''mean, logvar = model.encoder(test_x)\n        z = model.reparameterize(mean, logvar)\n        pred = model.decoder(z)'''\n        pred = model(x)\n        \n        fig = plt.figure(figsize=(16, 16))\n\n        for i in range(min(BATCH_SIZE,8)):\n            plt.subplot(4, 4, i + 1)\n            plt.imshow(pred[i,:,:,:], cmap='jet')\n            plt.axis('off')\n        plt.show()\n\n        fig1 = plt.figure(figsize=(16, 16))\n\n        for i in range(min(BATCH_SIZE,8)):\n            plt.subplot(4, 4, i + 1)\n            plt.imshow(x[i, :, :, ], cmap='jet')\n            plt.axis('off')\n\n        plt.show()\nplot_predictions(model, nc_images)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Calculating an optimal threshold\n\nNow I will compute an **anomaly score** for each input image, store these scores along with their corresponding labels, and then use the **ROC curve** to identify the optimal threshold for distinguishing between normal and anomalous data.","metadata":{}},{"cell_type":"code","source":"all_labels = []\nall_scores = []\n\nc = 0\nfor images, labels in dataset:  \n    if c % 1000 == 0: \n        print(c)\n    model1.mean, model1.logvar = model1.encoder(images)\n    output = model1.decoder(model1.reparameterize(model1.mean, model1.logvar))\n    anomaly_score = vaeloss(images, output, model1.mean, model1.logvar)\n    \n    all_labels.append(labels.numpy())  \n    all_scores.append(anomaly_score.numpy()) \n    c += 1\n\n# Convert lists to numpy arrays\nall_labels = np.array(all_labels)\nall_scores = np.array(all_scores)\n\n# Calculate the ROC curve\nfpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n\n# Determine the optimal threshold\noptimal_threshold = thresholds[np.argmax(tpr - fpr)]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T23:25:42.486553Z","iopub.execute_input":"2024-10-09T23:25:42.487347Z","iopub.status.idle":"2024-10-10T01:08:08.812485Z","shell.execute_reply.started":"2024-10-09T23:25:42.487314Z","shell.execute_reply":"2024-10-10T01:08:08.811449Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the ROC curve\ndef plot_roc_curve(y_true, anomaly_scores):\n    # Calculate ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true, anomaly_scores)\n    \n    # Calculate AUC\n    roc_auc = auc(fpr, tpr)\n    \n    # Plot ROC curve\n    plt.figure(figsize=(10, 8))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    \n    # Add threshold annotations\n    thresholds_to_show = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n    idx = np.searchsorted(thresholds, thresholds_to_show)\n    for i in idx:\n        plt.annotate(f'{thresholds[i]:.2f}', (fpr[i], tpr[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n\n    # Find and mark the optimal threshold\n    optimal_idx = np.argmax(tpr - fpr)\n    optimal_threshold = thresholds[optimal_idx]\n    plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=10, label=f'Optimal threshold: {optimal_threshold:.2f}')\n    plt.annotate(f'Optimal: {optimal_threshold:.2f}', (fpr[optimal_idx], tpr[optimal_idx]), \n                 textcoords=\"offset points\", xytext=(0,-20), ha='center', fontweight='bold')\n\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    plt.show()\n\n    return optimal_threshold\n\nplot_roc_curve(all_labels, all_scores)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T01:08:10.025167Z","iopub.execute_input":"2024-10-10T01:08:10.025532Z","iopub.status.idle":"2024-10-10T01:08:10.414791Z","shell.execute_reply.started":"2024-10-10T01:08:10.0255Z","shell.execute_reply":"2024-10-10T01:08:10.413697Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prediction (Calculating model pf1 score)","metadata":{}},{"cell_type":"code","source":"pred = list()\ny = list()\n\nfor images, labels in dataset.take(200):  \n    model1.mean, model1.logvar = model1.encoder(images)\n    output = model1.decoder(model1.reparameterize(model1.mean, model1.logvar))\n    error = vaeloss(images, output, model1.mean, model1.logvar)\n    \n    y.append(labels.numpy()[0])\n    if error > optimal_threshold:\n        pred.append(1)\n    else:\n        pred.append(0)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T01:44:17.662687Z","iopub.execute_input":"2024-10-10T01:44:17.663052Z","iopub.status.idle":"2024-10-10T01:44:45.783571Z","shell.execute_reply.started":"2024-10-10T01:44:17.663024Z","shell.execute_reply":"2024-10-10T01:44:45.78218Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pfbeta(labels, predictions, beta=1):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = predictions[idx]\n\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n    print(y_true_count)\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0\n\nresult = pfbeta(y,pred)\nresult","metadata":{"execution":{"iopub.status.busy":"2024-10-10T01:44:45.785718Z","iopub.execute_input":"2024-10-10T01:44:45.786029Z","iopub.status.idle":"2024-10-10T01:44:45.79836Z","shell.execute_reply.started":"2024-10-10T01:44:45.786001Z","shell.execute_reply":"2024-10-10T01:44:45.797269Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate number of cancer images in the batch used\nfor n, i in enumerate(y):\n    if i == 1:\n        print(n)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T01:44:55.799421Z","iopub.execute_input":"2024-10-10T01:44:55.799823Z","iopub.status.idle":"2024-10-10T01:44:55.805569Z","shell.execute_reply.started":"2024-10-10T01:44:55.799793Z","shell.execute_reply":"2024-10-10T01:44:55.804463Z"},"trusted":true},"outputs":[],"execution_count":null}]}